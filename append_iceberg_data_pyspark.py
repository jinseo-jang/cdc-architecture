from pyspark.sql import SparkSession
import google.auth
from google.auth.transport.requests import Request
import os

# 1. í™˜ê²½ ì„¤ì • (ì´ì „ê³¼ ë™ì¼)
project_id = "duper-project-1"
location = "us-central1"
catalog_id = "duper-project-1-iceberg-storage"
namespace = "iceberg_dataset"
table_name = "products_iceberg"


def get_access_token():
    credentials, _ = google.auth.default(
        scopes=["https://www.googleapis.com/auth/cloud-platform"]
    )
    credentials.refresh(Request())
    return credentials.token


access_token = get_access_token()

# 2. Spark ì„¸ì…˜ (ì´ì „ê³¼ ë™ì¼í•œ ì„¤ì • ìœ ì§€)
spark = (
    SparkSession.builder.appName("Iceberg_Metadata_Test")
    .config(f"spark.sql.catalog.{catalog_id}", "org.apache.iceberg.spark.SparkCatalog")
    .config(f"spark.sql.catalog.{catalog_id}.type", "rest")
    .config(
        f"spark.sql.catalog.{catalog_id}.uri",
        "https://biglake.googleapis.com/iceberg/v1/restcatalog",
    )
    .config(
        f"spark.sql.catalog.{catalog_id}.warehouse",
        f"bq://projects/{project_id}/locations/{location}",
    )
    .config(f"spark.sql.catalog.{catalog_id}.token", access_token)
    .config(f"spark.sql.catalog.{catalog_id}.header.x-goog-user-project", project_id)
    .config(
        f"spark.sql.catalog.{catalog_id}.io-impl",
        "org.apache.iceberg.gcp.gcs.GCSFileIO",
    )
    .getOrCreate()
)

# 3. ë°ì´í„° ì¶”ê°€ ì‚½ì… (ë‘ ë²ˆì§¸ ë°ì´í„°)
print(f"ğŸš€ '{table_name}'ì— ë‘ ë²ˆì§¸ ë°ì´í„°ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤...")

spark.sql(
    f"""
    INSERT INTO `{catalog_id}`.{namespace}.{table_name} 
    VALUES (2, 'metadata_test_item', 150.0, current_timestamp())
"""
)

print("âœ… ë°ì´í„° ì‚½ì… ì™„ë£Œ!")
